#!/usr/bin/env python
"""
Script for evaluating TF binding with trained model(s).

Use `predict.py -h` to see an auto-generated description of advanced options.
"""

import numpy as np
import pylab
import matplotlib
import pandas

import utils
import utils_metagencode
import pickle

# Standard library imports
import sys
import os
import errno
import argparse

def make_argument_parser():
    """
    Creates an ArgumentParser to read the options for this script from
    sys.argv
    """
    parser = argparse.ArgumentParser(
        description="Visualize results of a trained model.",
        epilog='\n'.join(__doc__.strip().split('\n')[1:]).strip(),
        formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument('--inputdir', '-i', type=str, required=True,
                        help='Folder containing input data')
    parser.add_argument('--modeldir', '-m', type=str, required=True, nargs='+',
                        help='Folder(s) containing trained model(s) generated by train.py.')
    parser.add_argument('--factor', '-f', type=str, required=True,
                        help='The transcription factor to evaluate.')
    parser.add_argument('--bed', '-b', type=str, required=True,
                        help='BED file containing intervals to predict on.')
    parser.add_argument('--outputfile', '-o', type=str, required=True,
                       help='The output filename.')
    return parser


def main():
    """
    The main executable function
    """
    parser = make_argument_parser()
    args = parser.parse_args()

    input_dir = args.inputdir
    model_dirs = args.modeldir
    tf = args.factor
    bed_file = args.bed
    output_file = args.outputfile

    print 'loading genome'
    genome = utils.load_genome()
    print 'loading test data'
    bigwig_names, datagen_bed, nonblacklist_bools = utils_metagencode.load_beddata(tf, genome, bed_file, input_dir)
    predicts = []
    print 'loading models and generating predictions'
    for model_dir in model_dirs:
        print 'loading', model_dir
        model_tfs, model_bigwig_names, model = utils.load_model(model_dir)
        assert tf in model_tfs
        assert bigwig_names == model_bigwig_names
        model_tf_index = model_tfs.index(tf)
        print 'predicting'
        model_predicts = model.predict_generator(datagen_bed, val_samples=len(datagen_bed), pickle_safe=True)
        if len(model_tfs) > 1:
            model_tf_predicts = model_predicts[:, model_tf_index]
        else:
            model_tf_predicts = model_predicts
        predicts.append(model_tf_predicts)
        datagen_bed.reset()
    print 'averaging predictions'
    averaged_predicts = sum(predicts)/len(predicts)
    final_scores = np.zeros(len(nonblacklist_bools))
    final_scores[nonblacklist_bools] = averaged_predicts
    print 'saving predictions'
    df = pandas.read_csv(bed_file, sep='\t', header=None)
    df[3] = final_scores
    df.to_csv(output_file, sep='\t', compression='gzip', float_format='%.3e', header=False, index=False)


if __name__ == '__main__':
    """
    See module-level docstring for a description of the script.
    """
    main()
